{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical data in `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`numpy`](https://docs.scipy.org/doc/numpy/) is a very powerful library for working with numerical data in Python. It introduces the __Array__ data structure, which can contain multi-dimensional numerical data. The `numpy` library is __not__ part of the Python standard library. However, it comes bundles with [Anaconda](01_anaconda.ipynb) so you should already have it installed. The usual way to import `numpy` is as follows:\n",
    "\n",
    "    import numpy as np\n",
    "    \n",
    "This gives us access to all the `numpy`-functions using the prefix `np`. This is a convention, and you should do the same in your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3, linewidth=75, edgeitems=1)\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to instantiate an array is by giving it a list or another iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_list = [1, 2, 5, 3]\n",
    "data_as_np = np.array(data_in_list)\n",
    "data_as_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data with `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numpy` library comes with a few functions that can read numerical data from text files. The `np.loadtxt`-function is a fast reader with some basic functionality for skipping header lines, converting values to floats, etc. For more sophisticated files the `np.genfromtxt`-function can be used. It also supports handling missing values, but is slower.\n",
    "\n",
    "Note that these functions take a filename as input, so that you do not need to use the built-in `open`-function to open a file beforehand. Assume we have a text-file containing data of the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.25     -89.75    0.022015    0.040741   -0.021861   -0.029058   -0.025845   -0.055643\r\n",
      "   180.25     -89.75    0.025000    0.041008    0.021540    0.028705    0.025741    0.055648\r\n",
      "     0.25       0.25   -0.045473   -0.013363   -0.029142   -0.034187   -0.026165   -0.070089\r\n",
      "   180.25       0.25    0.028523    0.039553   -0.002982   -0.035883    0.024974    0.071998\r\n",
      "     0.25      89.75   -0.010242   -0.028406    0.042345        -999   -0.025851   -0.070016\r\n",
      "   180.25      89.75   -0.013632   -0.028131   -0.042647   -0.029206    0.025918    0.070023\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/numpy_simple.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data can be loaded with a very simple `np.loadtxt`-command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.500e-01,  -8.975e+01,   2.201e-02,   4.074e-02,  -2.186e-02,\n",
       "         -2.906e-02,  -2.584e-02,  -5.564e-02],\n",
       "       [  1.802e+02,  -8.975e+01,   2.500e-02,   4.101e-02,   2.154e-02,\n",
       "          2.871e-02,   2.574e-02,   5.565e-02],\n",
       "       [  2.500e-01,   2.500e-01,  -4.547e-02,  -1.336e-02,  -2.914e-02,\n",
       "         -3.419e-02,  -2.617e-02,  -7.009e-02],\n",
       "       [  1.802e+02,   2.500e-01,   2.852e-02,   3.955e-02,  -2.982e-03,\n",
       "         -3.588e-02,   2.497e-02,   7.200e-02],\n",
       "       [  2.500e-01,   8.975e+01,  -1.024e-02,  -2.841e-02,   4.235e-02,\n",
       "         -9.990e+02,  -2.585e-02,  -7.002e-02],\n",
       "       [  1.802e+02,   8.975e+01,  -1.363e-02,  -2.813e-02,  -4.265e-02,\n",
       "         -2.921e-02,   2.592e-02,   7.002e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('data/numpy_simple.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays in `numpy` have a shape specifying how big the dataset is. In this case we have 6 rows and 8 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to lists and other sequences in Python, `numpy` arrays can be indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.500e-01,  -8.975e+01,   2.201e-02,   4.074e-02,  -2.186e-02,\n",
       "        -2.906e-02,  -2.584e-02,  -5.564e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]    # First row (= row 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.500e-01,   2.500e-01,  -4.547e-02,  -1.336e-02,  -2.914e-02,\n",
       "         -3.419e-02,  -2.617e-02,  -7.009e-02],\n",
       "       [  1.802e+02,   2.500e-01,   2.852e-02,   3.955e-02,  -2.982e-03,\n",
       "         -3.588e-02,   2.497e-02,   7.200e-02],\n",
       "       [  2.500e-01,   8.975e+01,  -1.024e-02,  -2.841e-02,   4.235e-02,\n",
       "         -9.990e+02,  -2.585e-02,  -7.002e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2:5]    # Rows 2, 3 and 4 (3rd, 4th and 5th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with multi-dimensional arrays (in this case 2-dimensional), we can specify each dimension in the index separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-999.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4, 5]    # Element in row 4, column 5 (5th row, 6th column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.25,  -89.75],\n",
       "       [ 180.25,  -89.75],\n",
       "       [   0.25,    0.25],\n",
       "       [ 180.25,    0.25],\n",
       "       [   0.25,   89.75],\n",
       "       [ 180.25,   89.75]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:, :2]    # All rows, first two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `numpy`-arrays most operations are vectorized. That means that we do not need to explicitly loop over the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.048,  0.047, -0.055,  0.022,  0.016, -0.017])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:, 4] + data[:, 6]    # Add columns 4 and 6 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.946,  1.057,  0.932,  1.075,  0.932,  1.073])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(data[:, -1])    # Exponentiate the last (-1) column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` also comes with summary functions like `sum`, `mean`, `std`, `var`, `median`, etc that can operate on a whole array or a given dimension (`axis`) of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.5223768750000009"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data)    # Calculate the mean of the whole array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.025e+01,   8.333e-02,   1.032e-03,   8.567e-03,  -5.458e-03,\n",
       "        -1.665e+02,  -2.047e-04,   3.202e-04])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data, axis=0)    # Calculate the mean of each column (along the rows, the 0th axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced reading of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most datafiles are not as clean as the simple datafile we have been working with above. Let us instead try to load the following file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified dataset based on Ocean Pole Load Tide Deformation Parameters\r\n",
      "from Self-Consistent Equilibrium Model of Ocean Pole Tide (Desai, 2002)\r\n",
      "Number_longitude_Grid_Points =         2\r\n",
      "First_longitude_degrees      =      0.25\r\n",
      "Last_longitude_degrees       =    180.25\r\n",
      "Longitude_step_degrees       =     180.0\r\n",
      "Number_latitude_grid_points  =         3\r\n",
      "First_latitude_degrees       =    -89.75\r\n",
      "Last_latitude_degrees        =     89.75\r\n",
      "Latitude_step_degrees        =      90.0\r\n",
      "Longitude   Latitude   u_r^R       u_r^I       u_n^R       u_n^I       u_e^R       u_e^I    \r\n",
      "(degrees)  (degrees)  (        )  (        )  (        )  (        )  (        )  (        )\r\n",
      "---------  ---------  ----------  ----------  ----------  ----------  ----------  ----------\r\n",
      "     0.25     -89.75    0.022015    0.040741   -0.021861   -0.029058   -0.025845   -0.055643\r\n",
      "   180.25     -89.75    0.025000    0.041008    0.021540    0.028705    0.025741    0.055648\r\n",
      "     0.25       0.25   -0.045473   -0.013363   -0.029142   -0.034187   -0.026165   -0.070089\r\n",
      "   180.25       0.25    0.028523    0.039553   -0.002982   -0.035883    0.024974    0.071998\r\n",
      "     0.25      89.75   -0.010242   -0.028406    0.042345        -999   -0.025851   -0.070016\r\n",
      "   180.25      89.75   -0.013632   -0.028131   -0.042647   -0.029206    0.025918    0.070023\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/numpy_header.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive use of `np.loadtxt` will fail because `numpy` tries to interpret the header as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'Simplified'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eff1fc9d70f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/numpy_header.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34mb'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: b'Simplified'"
     ]
    }
   ],
   "source": [
    "data2 = np.loadtxt('data/numpy_header.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we must give the `np.loadtxt` some more information. To get some help about a function and which parameters it takes, you can write a question mark after its name,\n",
    "\n",
    "    np.loadtxt?\n",
    "    \n",
    "or press `<shift>` and `<tab>` inside the paranthesis. Pressing `<shift>` and `<tab>` twice will give even more information.\n",
    "\n",
    "In this case, we notice that there is an argument called `skiprows` that can be used to ignore the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.loadtxt('data/numpy_header.txt', skiprows=13)\n",
    "np.allclose(data, data2)    # Test if data and data2 contains the same elements (within a tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking more closely at the data, we also notice that there is one datapoint with the value of -999 that probably designates a missing data point. We can convert this to a `nan`-value to handle it properly as we are reading the data. However, to do so we need to use the more sophisticated `np.genfromtxt`-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.500e-01,  -8.975e+01,   2.201e-02,   4.074e-02,  -2.186e-02,\n",
       "         -2.906e-02,  -2.584e-02,  -5.564e-02],\n",
       "       [  1.802e+02,  -8.975e+01,   2.500e-02,   4.101e-02,   2.154e-02,\n",
       "          2.871e-02,   2.574e-02,   5.565e-02],\n",
       "       [  2.500e-01,   2.500e-01,  -4.547e-02,  -1.336e-02,  -2.914e-02,\n",
       "         -3.419e-02,  -2.617e-02,  -7.009e-02],\n",
       "       [  1.802e+02,   2.500e-01,   2.852e-02,   3.955e-02,  -2.982e-03,\n",
       "         -3.588e-02,   2.497e-02,   7.200e-02],\n",
       "       [  2.500e-01,   8.975e+01,  -1.024e-02,  -2.841e-02,   4.235e-02,\n",
       "                nan,  -2.585e-02,  -7.002e-02],\n",
       "       [  1.802e+02,   8.975e+01,  -1.363e-02,  -2.813e-02,  -4.265e-02,\n",
       "         -2.921e-02,   2.592e-02,   7.002e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = np.genfromtxt('data/numpy_header.txt', skip_header=13,\n",
    "                      missing_values='-999', usemask=True).filled(np.nan)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually handling the missing data is a two-step process. First we create a masked array, where the mask denotes which data are missing. This can be seen if we look directly at the output from `np.genfromtxt` (note the single `True`-value in the mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data =\n",
       " [[0.25 -89.75 0.022015 0.040741 -0.021861 -0.029058 -0.025845 -0.055643]\n",
       " [180.25 -89.75 0.025 0.041008 0.02154 0.028705 0.025741 0.055648]\n",
       " [0.25 0.25 -0.045473 -0.013363 -0.029142 -0.034187 -0.026165 -0.070089]\n",
       " [180.25 0.25 0.028523 0.039553 -0.002982 -0.035883 0.024974 0.071998]\n",
       " [0.25 89.75 -0.010242 -0.028406 0.042345 -- -0.025851 -0.070016]\n",
       " [180.25 89.75 -0.013632 -0.028131 -0.042647 -0.029206 0.025918 0.070023]],\n",
       "             mask =\n",
       " [[False False False False False False False False]\n",
       " [False False False False False False False False]\n",
       " [False False False False False False False False]\n",
       " [False False False False False False False False]\n",
       " [False False False False False  True False False]\n",
       " [False False False False False False False False]],\n",
       "       fill_value = 1e+20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.genfromtxt('data/numpy_simple.txt', missing_values='-999', usemask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [`numpy` docs](https://docs.scipy.org/doc/numpy-dev/user/basics.io.genfromtxt.html) for more information about reading data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
